!pip install wordcloud
import wordcloud
from wordcloud import WordCloud
import matplotlib
import matplotlib.pyplot as plt
import jieba
#下載並讀入字典
# !wget https://raw.githubusercontent.com/fxsjy/jieba/master/extra_dict/dict.txt.big
jieba.load_userdict("./dict.txt.big")

#開啟檔案
txt_file_path = "./yahoo.txt"
with open(txt_file_path, "r")as fn:
    lines = fn.readlines()
    lines = list(map(lambda x: x.strip(),lines)) # 移除斷行字元


# 精確模式斷詞
tokens_1 = list(map(lambda x: list(jieba.cut(str(x), HMM=False)), lines))
word_count = {}
for sent in tokens_1: # 放入斷詞之後的變數
 for word in sent:
 if word not in word_count:
            word_count[word] = 0
        word_count[word] += 1

# 下載中文字型檔
!wget https://github.com/odek53r/Data-Science-Camp/raw/main/SourceHanSerifK-Light.otf

wordcloud = WordCloud(
        background_color = 'white',
        font_path = 'SourceHanSerifK-Light.otf', # 放入中文字型檔路徑
        colormap=matplotlib.cm.cubehelix,
        width = 1600,
        height = 800,
        margin = 2)

# wordcloud 套件 Input 需放入詞頻統計的 dict 型態變數
wordcloud = wordcloud.generate_from_frequencies(word_count) 
plt.figure(figsize=(20,10), facecolor='k')
plt.imshow(wordcloud)
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()


 
